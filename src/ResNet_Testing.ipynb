{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/sid/Desktop/Personel/SJSU/Semester III/CMPE 258- DL/Project/virtual_env/bin/python\n"
          ]
        }
      ],
      "source": [
        "!which python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-z103qRx1PUK",
        "outputId": "e54e93b5-bf74-4530-84c6-3b913aa7cf02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mediapipe\n",
            "  Obtaining dependency information for mediapipe from https://files.pythonhosted.org/packages/67/95/30e3aa1d00609c01435512aeddfc2eda694a24f8ff45c287a61f45fb6f3c/mediapipe-0.10.18-cp312-cp312-macosx_11_0_universal2.whl.metadata\n",
            "  Downloading mediapipe-0.10.18-cp312-cp312-macosx_11_0_universal2.whl.metadata (9.7 kB)\n",
            "Collecting absl-py (from mediapipe)\n",
            "  Obtaining dependency information for absl-py from https://files.pythonhosted.org/packages/a2/ad/e0d3c824784ff121c03cc031f944bc7e139a8f1870ffd2845cc2dd76f6c4/absl_py-2.1.0-py3-none-any.whl.metadata\n",
            "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting attrs>=19.1.0 (from mediapipe)\n",
            "  Obtaining dependency information for attrs>=19.1.0 from https://files.pythonhosted.org/packages/6a/21/5b6702a7f963e95456c0de2d495f67bf5fd62840ac655dc451586d23d39a/attrs-24.2.0-py3-none-any.whl.metadata\n",
            "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting flatbuffers>=2.0 (from mediapipe)\n",
            "  Obtaining dependency information for flatbuffers>=2.0 from https://files.pythonhosted.org/packages/41/f0/7e988a019bc54b2dbd0ad4182ef2d53488bb02e58694cd79d61369e85900/flatbuffers-24.3.25-py2.py3-none-any.whl.metadata\n",
            "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
            "Collecting jax (from mediapipe)\n",
            "  Obtaining dependency information for jax from https://files.pythonhosted.org/packages/a5/d5/1240192a0bc7b284bca9f753e69e92645afb82a6b2c3e1138520698938f4/jax-0.4.36-py3-none-any.whl.metadata\n",
            "  Downloading jax-0.4.36-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib (from mediapipe)\n",
            "  Obtaining dependency information for jaxlib from https://files.pythonhosted.org/packages/d3/46/05e70a1236ec3782333b3e9469f971c9d45af2aa0aebf602acd9d76292eb/jaxlib-0.4.36-cp312-cp312-macosx_11_0_arm64.whl.metadata\n",
            "  Downloading jaxlib-0.4.36-cp312-cp312-macosx_11_0_arm64.whl.metadata (1.0 kB)\n",
            "Collecting matplotlib (from mediapipe)\n",
            "  Obtaining dependency information for matplotlib from https://files.pythonhosted.org/packages/e5/52/3910833a073e7182ab3ae03810ed418f71c7fdcd65e2862cda1c6a14ffc1/matplotlib-3.9.3-cp312-cp312-macosx_11_0_arm64.whl.metadata\n",
            "  Downloading matplotlib-3.9.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (11 kB)\n",
            "Collecting numpy<2 (from mediapipe)\n",
            "  Obtaining dependency information for numpy<2 from https://files.pythonhosted.org/packages/75/5b/ca6c8bd14007e5ca171c7c03102d17b4f4e0ceb53957e8c44343a9546dcc/numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl.metadata\n",
            "  Using cached numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (61 kB)\n",
            "Collecting opencv-contrib-python (from mediapipe)\n",
            "  Obtaining dependency information for opencv-contrib-python from https://files.pythonhosted.org/packages/92/64/c1194510eaed272d86b53a08c790ca6ed1c450f06d401c49c8145fc46d40/opencv_contrib_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl.metadata\n",
            "  Downloading opencv_contrib_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl.metadata (20 kB)\n",
            "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
            "  Obtaining dependency information for protobuf<5,>=4.25.3 from https://files.pythonhosted.org/packages/51/49/d110f0a43beb365758a252203c43eaaad169fe7749da918869a8c991f726/protobuf-4.25.5-cp37-abi3-macosx_10_9_universal2.whl.metadata\n",
            "  Downloading protobuf-4.25.5-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Obtaining dependency information for sounddevice>=0.4.4 from https://files.pythonhosted.org/packages/6f/f6/6703fe7cf3d7b7279040c792aeec6334e7305956aba4a80f23e62c8fdc44/sounddevice-0.5.1-py3-none-macosx_10_6_x86_64.macosx_10_6_universal2.whl.metadata\n",
            "  Downloading sounddevice-0.5.1-py3-none-macosx_10_6_x86_64.macosx_10_6_universal2.whl.metadata (1.4 kB)\n",
            "Collecting sentencepiece (from mediapipe)\n",
            "  Obtaining dependency information for sentencepiece from https://files.pythonhosted.org/packages/49/0a/2fe387f825ac5aad5a0bfe221904882106cac58e1b693ba7818785a882b6/sentencepiece-0.2.0-cp312-cp312-macosx_11_0_arm64.whl.metadata\n",
            "  Downloading sentencepiece-0.2.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
            "Collecting CFFI>=1.0 (from sounddevice>=0.4.4->mediapipe)\n",
            "  Obtaining dependency information for CFFI>=1.0 from https://files.pythonhosted.org/packages/da/ee/fb72c2b48656111c4ef27f0f91da355e130a923473bf5ee75c5643d00cca/cffi-1.17.1-cp312-cp312-macosx_11_0_arm64.whl.metadata\n",
            "  Downloading cffi-1.17.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (1.5 kB)\n",
            "Collecting ml_dtypes>=0.4.0 (from jax->mediapipe)\n",
            "  Obtaining dependency information for ml_dtypes>=0.4.0 from https://files.pythonhosted.org/packages/1c/b7/a067839f6e435785f34b09d96938dccb3a5d9502037de243cb84a2eb3f23/ml_dtypes-0.5.0-cp312-cp312-macosx_10_9_universal2.whl.metadata\n",
            "  Downloading ml_dtypes-0.5.0-cp312-cp312-macosx_10_9_universal2.whl.metadata (21 kB)\n",
            "Collecting opt_einsum (from jax->mediapipe)\n",
            "  Obtaining dependency information for opt_einsum from https://files.pythonhosted.org/packages/23/cd/066e86230ae37ed0be70aae89aabf03ca8d9f39c8aea0dec8029455b5540/opt_einsum-3.4.0-py3-none-any.whl.metadata\n",
            "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting scipy>=1.10 (from jax->mediapipe)\n",
            "  Obtaining dependency information for scipy>=1.10 from https://files.pythonhosted.org/packages/c8/53/35b4d41f5fd42f5781dbd0dd6c05d35ba8aa75c84ecddc7d44756cd8da2e/scipy-1.14.1-cp312-cp312-macosx_12_0_arm64.whl.metadata\n",
            "  Downloading scipy-1.14.1-cp312-cp312-macosx_12_0_arm64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting contourpy>=1.0.1 (from matplotlib->mediapipe)\n",
            "  Obtaining dependency information for contourpy>=1.0.1 from https://files.pythonhosted.org/packages/6b/6a/7833cfae2c1e63d1d8875a50fd23371394f540ce809d7383550681a1fa64/contourpy-1.3.1-cp312-cp312-macosx_11_0_arm64.whl.metadata\n",
            "  Downloading contourpy-1.3.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.4 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib->mediapipe)\n",
            "  Obtaining dependency information for cycler>=0.10 from https://files.pythonhosted.org/packages/e7/05/c19819d5e3d95294a6f5947fb9b9629efb316b96de511b418c53d245aae6/cycler-0.12.1-py3-none-any.whl.metadata\n",
            "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib->mediapipe)\n",
            "  Obtaining dependency information for fonttools>=4.22.0 from https://files.pythonhosted.org/packages/3c/62/7ac990a52c2bb249e9de6de0036a24eba5a5a8e8446819ab5a5751a0a45e/fonttools-4.55.2-cp312-cp312-macosx_10_13_universal2.whl.metadata\n",
            "  Downloading fonttools-4.55.2-cp312-cp312-macosx_10_13_universal2.whl.metadata (164 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.0/165.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib->mediapipe)\n",
            "  Obtaining dependency information for kiwisolver>=1.3.1 from https://files.pythonhosted.org/packages/80/c5/57fa58276dfdfa612241d640a64ca2f76adc6ffcebdbd135b4ef60095098/kiwisolver-1.4.7-cp312-cp312-macosx_11_0_arm64.whl.metadata\n",
            "  Downloading kiwisolver-1.4.7-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/sid/Desktop/Personel/SJSU/Semester III/CMPE 258- DL/Project/virtual_env/lib/python3.12/site-packages (from matplotlib->mediapipe) (24.2)\n",
            "Collecting pillow>=8 (from matplotlib->mediapipe)\n",
            "  Obtaining dependency information for pillow>=8 from https://files.pythonhosted.org/packages/4f/d5/1caabedd8863526a6cfa44ee7a833bd97f945dc1d56824d6d76e11731939/pillow-11.0.0-cp312-cp312-macosx_11_0_arm64.whl.metadata\n",
            "  Using cached pillow-11.0.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.1 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib->mediapipe)\n",
            "  Obtaining dependency information for pyparsing>=2.3.1 from https://files.pythonhosted.org/packages/be/ec/2eb3cd785efd67806c46c13a17339708ddc346cbb684eade7a6e6f79536a/pyparsing-3.2.0-py3-none-any.whl.metadata\n",
            "  Downloading pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/sid/Desktop/Personel/SJSU/Semester III/CMPE 258- DL/Project/virtual_env/lib/python3.12/site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "Collecting pycparser (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe)\n",
            "  Obtaining dependency information for pycparser from https://files.pythonhosted.org/packages/13/a3/a812df4e2dd5696d1f351d58b8fe16a405b234ad2886a0dab9183fb78109/pycparser-2.22-py3-none-any.whl.metadata\n",
            "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
            "Requirement already satisfied: six>=1.5 in /Users/sid/Desktop/Personel/SJSU/Semester III/CMPE 258- DL/Project/virtual_env/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Downloading mediapipe-0.10.18-cp312-cp312-macosx_11_0_universal2.whl (49.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hUsing cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
            "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
            "Using cached numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\n",
            "Downloading protobuf-4.25.5-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.2/394.2 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.1-py3-none-macosx_10_6_x86_64.macosx_10_6_universal2.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.9/107.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "Downloading jax-0.4.36-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading jaxlib-0.4.36-cp312-cp312-macosx_11_0_arm64.whl (78.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.9.3-cp312-cp312-macosx_11_0_arm64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading opencv_contrib_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl (63.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading sentencepiece-0.2.0-cp312-cp312-macosx_11_0_arm64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cffi-1.17.1-cp312-cp312-macosx_11_0_arm64.whl (178 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.8/178.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contourpy-1.3.1-cp312-cp312-macosx_11_0_arm64.whl (255 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.4/255.4 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.55.2-cp312-cp312-macosx_10_13_universal2.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading kiwisolver-1.4.7-cp312-cp312-macosx_11_0_arm64.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.5.0-cp312-cp312-macosx_10_9_universal2.whl (750 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.2/750.2 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached pillow-11.0.0-cp312-cp312-macosx_11_0_arm64.whl (3.0 MB)\n",
            "Downloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.9/106.9 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.14.1-cp312-cp312-macosx_12_0_arm64.whl (29.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.9/29.9 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.6/117.6 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece, flatbuffers, pyparsing, pycparser, protobuf, pillow, opt_einsum, numpy, kiwisolver, fonttools, cycler, attrs, absl-py, scipy, opencv-contrib-python, ml_dtypes, contourpy, CFFI, sounddevice, matplotlib, jaxlib, jax, mediapipe\n",
            "Successfully installed CFFI-1.17.1 absl-py-2.1.0 attrs-24.2.0 contourpy-1.3.1 cycler-0.12.1 flatbuffers-24.3.25 fonttools-4.55.2 jax-0.4.36 jaxlib-0.4.36 kiwisolver-1.4.7 matplotlib-3.9.3 mediapipe-0.10.18 ml_dtypes-0.5.0 numpy-1.26.4 opencv-contrib-python-4.10.0.84 opt_einsum-3.4.0 pillow-11.0.0 protobuf-4.25.5 pycparser-2.22 pyparsing-3.2.0 scipy-1.14.1 sentencepiece-0.2.0 sounddevice-0.5.1\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Collecting joblib\n",
            "  Obtaining dependency information for joblib from https://files.pythonhosted.org/packages/91/29/df4b9b42f2be0b623cbd5e2140cafcaa2bef0759a00b7b70104dcfe2fb51/joblib-1.4.2-py3-none-any.whl.metadata\n",
            "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "Installing collected packages: joblib\n",
            "Successfully installed joblib-1.4.2\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Collecting tqdm\n",
            "  Obtaining dependency information for tqdm from https://files.pythonhosted.org/packages/d0/30/dc54f88dd4a2b5dc8a0279bdd7270e735851848b762aeb1c1184ed1f6b14/tqdm-4.67.1-py3-none-any.whl.metadata\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Installing collected packages: tqdm\n",
            "Successfully installed tqdm-4.67.1\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Collecting opencv-python\n",
            "  Obtaining dependency information for opencv-python from https://files.pythonhosted.org/packages/66/82/564168a349148298aca281e342551404ef5521f33fba17b388ead0a84dc5/opencv_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl.metadata\n",
            "  Downloading opencv_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /Users/sid/Desktop/Personel/SJSU/Semester III/CMPE 258- DL/Project/virtual_env/lib/python3.12/site-packages (from opencv-python) (1.26.4)\n",
            "Downloading opencv_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl (54.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opencv-python\n",
            "Successfully installed opencv-python-4.10.0.84\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Install MediaPipe\n",
        "!pip install mediapipe\n",
        "\n",
        "# Install joblib (usually pre-installed, but just in case)\n",
        "!pip install joblib\n",
        "\n",
        "# Install tqdm for progress bars\n",
        "!pip install tqdm\n",
        "\n",
        "# If you need a specific version of OpenCV\n",
        "!pip install opencv-python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "INPUT_VIDEO_PATH = \"input_videos/pushup_010.mp4\"\n",
        "OUTPUT_VIDEO_PATH = \"output_videos/pushup_010.mp4\"\n",
        "\n",
        "# Model & Testing Paths\n",
        "MODEL_PATH = 'trained_model_files/final_trained_model.pth'\n",
        "SCALER_PATH = 'trained_model_files/scaler.pkl'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/sid/Desktop/Personel/SJSU/Semester III/CMPE 258- DL/Project\n",
            "/Users/sid/Desktop/Personel/SJSU/Semester III/CMPE 258- DL/Project/input_videos/pushup_010.mp4\n",
            "/Users/sid/Desktop/Personel/SJSU/Semester III/CMPE 258- DL/Project/output_videos/pushup_010.mp4\n",
            "/Users/sid/Desktop/Personel/SJSU/Semester III/CMPE 258- DL/Project/trained_model_files/final_trained_model.pth\n",
            "/Users/sid/Desktop/Personel/SJSU/Semester III/CMPE 258- DL/Project/trained_model_files/scaler.pkl\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "root_path = os.path.dirname(os.path.abspath(''))\n",
        "print(root_path)\n",
        "\n",
        "INPUT_VIDEO_PATH = os.path.join(root_path, INPUT_VIDEO_PATH)\n",
        "OUTPUT_VIDEO_PATH = os.path.join(root_path, OUTPUT_VIDEO_PATH)\n",
        "\n",
        "# Model & Testing Paths\n",
        "MODEL_PATH = os.path.join(root_path, MODEL_PATH)\n",
        "SCALER_PATH = os.path.join(root_path, SCALER_PATH)\n",
        "\n",
        "print(INPUT_VIDEO_PATH)\n",
        "print(OUTPUT_VIDEO_PATH)\n",
        "print(MODEL_PATH)\n",
        "print(SCALER_PATH)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0s15d22P15W5",
        "outputId": "d78e885e-9ece-45d8-9c88-283a1922a92f"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import joblib\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define the model architecture (must match the training architecture)\n",
        "class Conv3DBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3,\n",
        "                 stride=1, padding=1):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "        self.bn = nn.BatchNorm3d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.relu(self.bn(self.conv(x)))\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = Conv3DBlock(in_channels, out_channels)\n",
        "        self.conv2 = Conv3DBlock(out_channels, out_channels)\n",
        "        self.downsample = None\n",
        "        if in_channels != out_channels:\n",
        "            self.downsample = nn.Sequential(\n",
        "                nn.Conv3d(in_channels, out_channels, kernel_size=1, stride=1),\n",
        "                nn.BatchNorm3d(out_channels)\n",
        "            )\n",
        "        self.relu = nn.ReLU(inplace=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "        out = out + identity\n",
        "        return self.relu(out)\n",
        "\n",
        "class ResNet3D(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=2, input_channels=8):\n",
        "        super().__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = Conv3DBlock(input_channels, 64, kernel_size=7, stride=2, padding=3)\n",
        "        self.maxpool = nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels))\n",
        "        self.in_channels = out_channels\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(2).unsqueeze(-1)  # Shape: [batch_size, channels, 1, sequence_length, 1]\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "def resnet3d18(num_classes=2, input_channels=8):\n",
        "    return ResNet3D(ResidualBlock, [2, 2, 2, 2], num_classes, input_channels)\n",
        "\n",
        "# Load the trained model\n",
        "model = resnet3d18(num_classes=2, input_channels=8)\n",
        "model.load_state_dict(torch.load(MODEL_PATH, map_location=torch.device('cpu')))\n",
        "model.eval()\n",
        "\n",
        "# Load the scaler\n",
        "scaler = joblib.load(SCALER_PATH)\n",
        "\n",
        "# Initialize MediaPipe Pose for pose estimation\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose(static_image_mode=False,\n",
        "                    min_detection_confidence=0.5,\n",
        "                    min_tracking_confidence=0.5)\n",
        "\n",
        "def calculate_angle(a, b, c):\n",
        "    \"\"\"Calculate the angle between three points.\"\"\"\n",
        "    a = np.array(a)\n",
        "    b = np.array(b)\n",
        "    c = np.array(c)\n",
        "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - \\\n",
        "              np.arctan2(a[1] - b[1], a[0] - b[0])\n",
        "    angle = np.abs(radians * 180.0 / np.pi)\n",
        "    if angle > 180.0:\n",
        "        angle = 360 - angle\n",
        "    return float(angle)\n",
        "\n",
        "def extract_features(frame):\n",
        "    \"\"\"Extract features from a single frame.\"\"\"\n",
        "    return [\n",
        "        frame['left_arm_angle'],\n",
        "        frame['right_arm_angle'],\n",
        "        frame['landmarks'][11][1],  # LEFT_SHOULDER y-coordinate\n",
        "        frame['landmarks'][12][1],  # RIGHT_SHOULDER y-coordinate\n",
        "        frame['landmarks'][13][1],  # LEFT_ELBOW y-coordinate\n",
        "        frame['landmarks'][14][1],  # RIGHT_ELBOW y-coordinate\n",
        "        frame['landmarks'][15][1],  # LEFT_WRIST y-coordinate\n",
        "        frame['landmarks'][16][1]   # RIGHT_WRIST y-coordinate\n",
        "    ]\n",
        "\n",
        "def preprocess_video(video_path, sequence_length=100):\n",
        "    \"\"\"Preprocess the video and extract features.\"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    preprocessed_data = []\n",
        "    frames = []  # Store frames for visualization\n",
        "\n",
        "    for frame_idx in tqdm(range(frame_count), desc=\"Processing Video\"):\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frames.append(frame.copy())  # Save the frame for later visualization\n",
        "\n",
        "        # Convert the image to RGB and process it with MediaPipe\n",
        "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        results = pose.process(image_rgb)\n",
        "\n",
        "        if results.pose_landmarks:\n",
        "            landmarks = results.pose_landmarks.landmark\n",
        "\n",
        "            # Extract relevant landmarks\n",
        "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
        "                             landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
        "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
        "                              landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
        "            left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,\n",
        "                          landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
        "            right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
        "                           landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
        "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
        "                          landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
        "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
        "                           landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
        "\n",
        "            # Calculate angles\n",
        "            left_arm_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
        "            right_arm_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
        "\n",
        "            preprocessed_data.append({\n",
        "                'frame': frame_idx,\n",
        "                'left_arm_angle': left_arm_angle,\n",
        "                'right_arm_angle': right_arm_angle,\n",
        "                'landmarks': [(landmark.x, landmark.y, landmark.z) for landmark in landmarks]\n",
        "            })\n",
        "        else:\n",
        "            # If no landmarks detected, append zeros\n",
        "            preprocessed_data.append({\n",
        "                'frame': frame_idx,\n",
        "                'left_arm_angle': 0.0,\n",
        "                'right_arm_angle': 0.0,\n",
        "                'landmarks': [(0.0, 0.0, 0.0)] * 33  # Assuming 33 landmarks\n",
        "            })\n",
        "\n",
        "    cap.release()\n",
        "    return preprocessed_data, frames\n",
        "\n",
        "def visualize_results(frames, predicted_class, confidence):\n",
        "    \"\"\"Overlay the prediction on video frames and save the result.\"\"\"\n",
        "    # Define the label and color based on the prediction\n",
        "    if predicted_class == 1:\n",
        "        label = f'Correct Form ({confidence * 100:.2f}%)'\n",
        "        color = (0, 255, 0)  # Green for correct\n",
        "    else:\n",
        "        label = f'Incorrect Form ({confidence * 100:.2f}%)'\n",
        "        color = (0, 0, 255)  # Red for incorrect\n",
        "\n",
        "    # Initialize video writer\n",
        "    height, width, _ = frames[0].shape\n",
        "    output_path = OUTPUT_VIDEO_PATH\n",
        "    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'),\n",
        "                          20, (width, height))\n",
        "\n",
        "    for frame in frames:\n",
        "        # Overlay text on the frame\n",
        "        cv2.putText(frame, label, (50, 50), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    1.5, color, 3)\n",
        "        out.write(frame)\n",
        "\n",
        "    out.release()\n",
        "    print(f\"Visualization saved as {output_path}\")\n",
        "\n",
        "def main():\n",
        "    # Path to your new video file\n",
        "    video_path = INPUT_VIDEO_PATH  # Update this path if necessary\n",
        "\n",
        "    # Preprocess the video and extract features\n",
        "    preprocessed_data, frames = preprocess_video(video_path)\n",
        "\n",
        "    # Extract features from preprocessed data\n",
        "    features = np.zeros((len(preprocessed_data), 8))\n",
        "    for i, frame in enumerate(preprocessed_data):\n",
        "        features[i] = extract_features(frame)\n",
        "\n",
        "    # Normalize features using the saved scaler\n",
        "    features_normalized = scaler.transform(features)\n",
        "\n",
        "    # Standardize sequence length\n",
        "    sequence_length = 100  # Same as during training\n",
        "    if len(features_normalized) < sequence_length:\n",
        "        pad_length = sequence_length - len(features_normalized)\n",
        "        features_normalized = np.pad(features_normalized, ((0, pad_length), (0, 0)), mode='constant')\n",
        "    elif len(features_normalized) > sequence_length:\n",
        "        features_normalized = features_normalized[:sequence_length]\n",
        "\n",
        "    # Prepare input tensor\n",
        "    input_tensor = torch.FloatTensor(features_normalized).permute(1, 0).unsqueeze(0)\n",
        "\n",
        "    # Make prediction\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)\n",
        "        probabilities = torch.softmax(output, dim=1)\n",
        "        predicted_class = torch.argmax(probabilities, dim=1).item()\n",
        "        confidence = probabilities[0, predicted_class].item()\n",
        "\n",
        "    # Output result\n",
        "    if predicted_class == 1:\n",
        "        print(f\"The push-up form is **correct** with confidence {confidence * 100:.2f}%\")\n",
        "    else:\n",
        "        print(f\"The push-up form is **incorrect** with confidence {confidence * 100:.2f}%\")\n",
        "\n",
        "    # Visualize the results\n",
        "    visualize_results(frames, predicted_class, confidence)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
